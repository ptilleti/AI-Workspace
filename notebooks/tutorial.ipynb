{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3cbac3",
   "metadata": {},
   "source": [
    "# üìö Building Your First AI Chatbot - Interactive Tutorial\n",
    "\n",
    "Welcome! This notebook will guide you through building an AI chatbot that can answer questions about PDF documents.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "1. How LLMs (Large Language Models) work\n",
    "2. Processing PDF documents\n",
    "3. Context Augmented Generation (CAG)\n",
    "4. Interacting with AI APIs\n",
    "5. Building a complete chatbot\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic Python knowledge\n",
    "- OpenAI API key (or we'll use a free alternative)\n",
    "- A PDF file to test with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a57df",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Installation\n",
    "\n",
    "First, let's make sure we have all the required packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this once)\n",
    "# Uncomment the line below if packages are not installed\n",
    "# !pip install openai python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6483ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd16ef",
   "metadata": {},
   "source": [
    "## Step 2: Understanding PDFs and Text Extraction\n",
    "\n",
    "Before we can chat about a PDF, we need to extract its text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "\n",
    "# Let's extract text from a PDF\n",
    "pdf_path = \"../data/sample.pdf\"  # Change this to your PDF\n",
    "\n",
    "# Check if file exists\n",
    "if Path(pdf_path).exists():\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = pypdf.PdfReader(file)\n",
    "        \n",
    "        print(f\"üìÑ PDF Info:\")\n",
    "        print(f\"   Pages: {len(pdf_reader.pages)}\")\n",
    "        print(f\"   Metadata: {pdf_reader.metadata}\")\n",
    "        \n",
    "        # Extract first page text\n",
    "        first_page = pdf_reader.pages[0]\n",
    "        text = first_page.extract_text()\n",
    "        \n",
    "        print(f\"\\nüìù First 500 characters:\")\n",
    "        print(text[:500])\n",
    "else:\n",
    "    print(\"‚ùå PDF file not found!\")\n",
    "    print(\"üí° Add a PDF to the data/ folder and update the path above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8257a8",
   "metadata": {},
   "source": [
    "## Step 3: Understanding LLMs (Large Language Models)\n",
    "\n",
    "### What is an LLM?\n",
    "- A neural network trained on massive amounts of text\n",
    "- Predicts the next word/token based on previous context\n",
    "- Examples: GPT-4, Claude, Llama, Gemini\n",
    "\n",
    "### Key Concepts:\n",
    "- **Tokens**: Words or word pieces (1 token ‚âà 4 characters)\n",
    "- **Context Window**: Max tokens the model can process at once\n",
    "- **Temperature**: Controls randomness (0=deterministic, 1=creative)\n",
    "- **System Prompt**: Instructions for how the AI should behave\n",
    "- **User Prompt**: Your actual question or request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Simple example: asking the LLM a question\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # Using the cheaper, faster model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful teacher.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain what an AI agent is in one simple sentence.\"}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"ü§ñ AI Response:\\n{answer}\")\n",
    "print(f\"\\nüìä Tokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204abdcc",
   "metadata": {},
   "source": [
    "## Step 4: Context Augmented Generation (CAG)\n",
    "\n",
    "### The Magic of CAG:\n",
    "1. Extract text from PDF\n",
    "2. Send the text + question to the LLM\n",
    "3. LLM answers based on the provided context\n",
    "\n",
    "### CAG vs RAG:\n",
    "- **CAG**: Send entire document as context (simple, works for smaller docs)\n",
    "- **RAG**: Search for relevant chunks, only send those (better for large docs)\n",
    "\n",
    "For learning, CAG is perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract full PDF text\n",
    "def extract_full_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = pypdf.PdfReader(file)\n",
    "        text_parts = []\n",
    "        \n",
    "        for page in pdf_reader.pages:\n",
    "            text_parts.append(page.extract_text())\n",
    "        \n",
    "        return \"\\n\\n\".join(text_parts)\n",
    "\n",
    "# Try it (if you have a PDF)\n",
    "if Path(pdf_path).exists():\n",
    "    full_text = extract_full_pdf(pdf_path)\n",
    "    \n",
    "    print(f\"üìä Extraction Stats:\")\n",
    "    print(f\"   Characters: {len(full_text):,}\")\n",
    "    print(f\"   Words: {len(full_text.split()):,}\")\n",
    "    print(f\"   Est. Tokens: {len(full_text) // 4:,}\")\n",
    "    \n",
    "    # Store for next step\n",
    "    pdf_content = full_text\n",
    "else:\n",
    "    print(\"Add a PDF to test this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e04f0",
   "metadata": {},
   "source": [
    "## Step 5: Building the Chatbot!\n",
    "\n",
    "Now let's put it all together and create our PDF chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0426daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_pdf_question(question, pdf_content):\n",
    "    \"\"\"\n",
    "    Ask a question about the PDF content.\n",
    "    This is CAG in action!\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    # Build the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a helpful assistant that answers questions based on \"\n",
    "                \"the provided document. Use only information from the document. \"\n",
    "                \"If the answer isn't in the document, say so clearly.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Document content:\\n\\n{pdf_content}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Get response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    tokens = response.usage.total_tokens\n",
    "    \n",
    "    return answer, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64bb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chatbot!\n",
    "if 'pdf_content' in locals():\n",
    "    question = \"What is this document about? Give me a brief summary.\"\n",
    "    \n",
    "    print(f\"‚ùì Question: {question}\\n\")\n",
    "    answer, tokens = ask_pdf_question(question, pdf_content)\n",
    "    print(f\"ü§ñ Answer: {answer}\")\n",
    "    print(f\"\\nüìä Tokens used: {tokens}\")\n",
    "else:\n",
    "    print(\"Add a PDF first to test the chatbot!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba545357",
   "metadata": {},
   "source": [
    "## Step 6: Try Your Own Questions!\n",
    "\n",
    "Now you can ask any question about your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive question answering\n",
    "if 'pdf_content' in locals():\n",
    "    # Try different questions:\n",
    "    questions = [\n",
    "        \"What are the main topics covered?\",\n",
    "        \"List any key concepts or terms\",\n",
    "        \"What's the most important takeaway?\"\n",
    "    ]\n",
    "    \n",
    "    for q in questions:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚ùì {q}\")\n",
    "        print('='*60)\n",
    "        answer, _ = ask_pdf_question(q, pdf_content)\n",
    "        print(f\"ü§ñ {answer}\")\n",
    "else:\n",
    "    print(\"Add a PDF to the data/ folder to start chatting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcb442",
   "metadata": {},
   "source": [
    "## üéì What You've Learned!\n",
    "\n",
    "Congratulations! You've now built a working AI chatbot. Here's what you learned:\n",
    "\n",
    "1. **PDF Processing**: How to extract text from documents\n",
    "2. **LLM Interaction**: How to send prompts and get responses\n",
    "3. **CAG**: How to use context to make AI more accurate\n",
    "4. **Prompt Engineering**: Crafting system and user prompts\n",
    "5. **Token Management**: Understanding costs and limits\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Ready to level up? Here are ideas:\n",
    "\n",
    "1. **Add RAG**: Learn vector databases (ChromaDB) for large documents\n",
    "2. **Memory**: Make the chatbot remember conversation history\n",
    "3. **Multi-PDF**: Handle multiple documents at once\n",
    "4. **Local Models**: Use Ollama to run LLMs locally (free!)\n",
    "5. **Web Interface**: Build a UI with Streamlit or Gradio\n",
    "6. **Advanced Agents**: Add tools, function calling, chains\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs)\n",
    "- [LangChain](https://python.langchain.com/) - Framework for LLM apps\n",
    "- [Ollama](https://ollama.ai/) - Run local models\n",
    "- [ChromaDB](https://www.trychroma.com/) - Vector database for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43526b",
   "metadata": {},
   "source": [
    "## üí° Exercises\n",
    "\n",
    "Try these challenges:\n",
    "\n",
    "1. Modify the temperature parameter - how does it change responses?\n",
    "2. Try different system prompts - make it formal, casual, or expert-level\n",
    "3. Count tokens in your PDF - will it fit in the context window?\n",
    "4. Add error handling for when questions aren't answerable\n",
    "5. Create a conversation history feature"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
